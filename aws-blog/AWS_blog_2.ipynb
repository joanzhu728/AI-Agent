{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99d628e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from agents import Agent, Runner, trace, function_tool, OpenAIChatCompletionsModel\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from typing import Dict\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pypandoc\n",
    "pypandoc.download_pandoc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662a7241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai = OpenAI()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c89ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt for writter\n",
    "\n",
    "writter_system_prompt = \"\"\"You are writing a series of articles as study guides for topics related to the AWS Advanced Networking Exam. The course guide can be found here: https://d1.awsstatic.com/onedam/marketing-channels/website/aws/en_US/certification/approved/pdfs/docs-advnetworking-spec/AWS-Certified-Advanced-Networking-Specialty_Exam-Guide.pdf.\n",
    "\n",
    "Please draft an article in the style of Bit the Chipmunk. Bit the Chipmunk is a cute, furry, and friendly woodland creature who also happens to be an AWS expert. He from time to time uses language and expressions that remind us that he is a chipmunk, for example by using nut or forest related metaphors or examples. However, do not make more than 5 chipmunk references in an entire article, and keep these references limitted to the introduction paragraph and the concluding paragraph -- do not include these references anywhere else.\n",
    "\n",
    "Use your own knowledge and search AWS documentation, blogs, and white papers as sources for the content.\n",
    "\n",
    "Include a Further Reading section with useful links related to the content of the article that you generate. Also, please include a brief introduction to the topic at the start of the article. Keep the tone light and friendly -- avoid matching the style of the source documents. Be sure to include exam scenarios and exam traps.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd26572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generate_article function\n",
    "\n",
    "def generate_article(topic: str) -> str:\n",
    "    \"\"\"Use OpenAI to generate the article.\"\"\"\n",
    "    prompt = [{\"role\": \"system\", \"content\": writter_system_prompt}] + [{\"role\": \"user\", \"content\": f\"Write an article for {topic}.\"}]\n",
    "    # response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=prompt, tools={\"web\":{}})\n",
    "    response = openai.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # model=\"gpt-5\",\n",
    "    input=prompt,\n",
    "    tools=[{\n",
    "        \"type\": \"web_search\"\n",
    "    }],\n",
    ")\n",
    "    return response.output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49988e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "# Pydantic is a powerful Python library used for data validation and data parsing â€” it makes sure that the data youâ€™re working with is the right type, structure, and format.\n",
    "# Itâ€™s most famous for being the backbone of frameworks like FastAPI, where it automatically validates incoming API data.\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Revision(BaseModel):\n",
    "    no_more_revision: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a7a7ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt for reviewer\n",
    "\n",
    "reviewer_system_prompt = \"\"\"You are an expert in the AWS Advanced Networking. You will evaluate an article written by the writter agent about a topic from the AWS Advanced Networking Exam.\n",
    "\n",
    "The agent is given the following instructions:\n",
    "\"writing a series of articles as study guides for topics related to the AWS Advanced Networking Exam. The course guide can be found here: https://d1.awsstatic.com/onedam/marketing-channels/website/aws/en_US/certification/approved/pdfs/docs-advnetworking-spec/AWS-Certified-Advanced-Networking-Specialty_Exam-Guide.pdf.\n",
    "\n",
    "Please draft an article in the style of Bit the Chipmunk. Bit the Chipmunk is a cute, furry, and friendly woodland creature who also happens to be an AWS expert. He from time to time uses language and expressions that remind us that he is a chipmunk, for example by using nut or forest related metaphors or examples. However, do not make more than 5 chipmunk references in an entire article, and keep these references limitted to the introduction paragraph and the concluding paragraph -- do not include these references anywhere else.\n",
    "\n",
    "Use your own knowledge and search AWS documentation, blogs, and white papers as sources for the content.\n",
    "\n",
    "Include a Further Reading section with useful links related to the content of the article that you generate. Also, please include a brief introduction to the topic at the start of the article. Keep the tone light and friendly -- avoid matching the style of the source documents. Be sure to include exam scenarios and exam traps.\"\n",
    "\n",
    "Please evaluate the article written by the agent for accuracy and completeness. By accuracy, I mean \"does it contain correct information\". By completeness, I mean \"does it miss any important cases or topics?\"\n",
    "Make sure that the new article's style is in alignment with other articles which are already posted on https://www.bits-guides.com/\n",
    "If the article is good enough to publish, set no_more_revision as true. Otherwise, set no_more_revision as false and provide your reasoning about why it needs more revision.\n",
    "\n",
    "Respond only in valid JSON format with the following fields without extra text:\n",
    "{\n",
    "    \"no_more_revision\": true or false,\n",
    "    \"feedback\": \"your reasoning\"\n",
    "}\n",
    "Use \\\\n for newlines inside strings.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667edeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define review_article function\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "# model_name = \"gemini-2.5-pro\"\n",
    "\n",
    "import json, re\n",
    "\n",
    "def review_article(article: str) -> Revision:\n",
    "    \"\"\"Use Gemini to review the OpenAI-generated article.\"\"\"\n",
    "    prompt = [{\"role\": \"system\", \"content\": reviewer_system_prompt}] + [{\"role\": \"user\", \"content\": f\"\\n\\nArticle:\\n{article}.\"}]\n",
    "    response = gemini.chat.completions.create(model=model_name, messages=prompt)\n",
    "    result = response.choices[0].message.content\n",
    "\n",
    "    # Convert the type of feedback from string to json dict\n",
    "    # # Try to find a JSON block in the string\n",
    "    match = re.search(r'\\{.*\\}', result, re.DOTALL)\n",
    "    if match:\n",
    "        json_text = match.group(0)\n",
    "        result_json = json.loads(json_text)\n",
    "    else:\n",
    "        print(\"No valid JSON found in feedback.\")\n",
    "    \n",
    "    return result_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3054e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define revise_article function\n",
    "\n",
    "def revise_article(article, feedback) -> str:\n",
    "    \"\"\"Use OpenAI to revise the article based on Gemini's feedback.\"\"\"\n",
    "    prompt = [{\"role\": \"system\", \"content\": writter_system_prompt}] + [{\"role\": \"user\", \"content\": f\"Revise the article based on the feedback provided.\\n\\nArticle:\\n{article}\\n\\nFeedback:\\n{feedback[\"feedback\"]}\"}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=prompt)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1736181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_topic(topic):\n",
    "\n",
    "    accepted_article = None\n",
    "    article = generate_article(topic)\n",
    "\n",
    "    for round_num in range(3):  # up to 3 review-revise rounds\n",
    "        print(f\"\\n--- Round {round_num + 1}: Review ---\\n\")\n",
    "        feedback = review_article(article)\n",
    "        print(feedback)\n",
    "\n",
    "        if feedback[\"no_more_revision\"]:\n",
    "            accepted_article = article\n",
    "            print(\"\\nâœ… Reviewer approved this version.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"\\nâœï¸ Revising article according to feedback...\\n\")\n",
    "            article = revise_article(article, feedback)\n",
    "\n",
    "    # If no explicit approval, assume final version\n",
    "    if not accepted_article:\n",
    "        print(\"\\n=== ðŸ ARTICLE IS NOT ACCEPTED AFTER 3 ROUND===\\n\")\n",
    "        status = \"Incomplete\"\n",
    "    else:\n",
    "        print(\"\\n=== ðŸ FINAL ACCEPTED ARTICLE ===\\n\")\n",
    "        print(accepted_article)\n",
    "        status = \"Completed\"\n",
    "\n",
    "    return status, accepted_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83199aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing topic: Cross Account Resource Sharing\n",
      "\n",
      "--- Round 1: Review ---\n",
      "\n",
      "{'no_more_revision': False, 'feedback': \"This is an excellent and comprehensive article that is very close to being ready for publication. The structure, tone, and focus on exam-specific details are all top-notch.\\n\\nHowever, there is one minor but important factual error that needs correction:\\n\\nIn the section 'Centralized connectivity: AWS Transit Gateway (TGW) and AWS Cloud WAN', under 'TGW sharing', the article states: 'In Sept 2024, AWS added Security Group Referencing...'. The feature was actually launched in September 2023, not 2024. Please correct this date to avoid confusion. A simple change to 'In late 2023, AWS added...' or simply 'AWS recently added...' would be sufficient.\\n\\nOnce this small correction is made, the article will be accurate and complete.\"}\n",
      "\n",
      "âœï¸ Revising article according to feedback...\n",
      "\n",
      "\n",
      "--- Round 2: Review ---\n",
      "\n",
      "{'no_more_revision': False, 'feedback': \"This is a very well-structured and comprehensive article that covers the key cross-account sharing patterns for the AWS Advanced Networking exam. The tone is excellent and fits the persona perfectly. However, there is a significant factual error in the 'Exam Traps' section that needs to be corrected before publishing.\\n\\n**Reasoning for Revision:**\\n\\nThe section on 'Security Group Referencing' contains an inaccuracy. Specifically:\\n\\n1.  **Incorrect 'Exam Trap':** The trap states, 'Security Group Referencing is **inbound only within the same TGW/Region**'. This is incorrect and misleading.\\n    *   For **VPC Peering**, you can reference a security group from a peered VPC (in another account, same region) in **both inbound and outbound** rules of your security groups. It is not 'inbound only'.\\n    *   For **AWS Transit Gateway**, you cannot directly reference a security group in another attached VPC within your own security group rules. Access control across a TGW is managed by routing, NACLs, and potentially firewalls in an inspection VPC. The statement as written is confusing and doesn't apply to TGW.\\n\\n**Suggested Changes:**\\n\\n1.  **Revise the 'Security Group Referencing' point under 'Key Patterns'.** Clarify that this primarily applies to VPC Peering. A better description would be: 'For VPCs connected via VPC Peering in the same region, you can reference a security group from the peered VPC in your own security group rules. This allows for stateful, instance-level security control across the peering connection.'\\n\\n2.  **Replace the incorrect 'Exam Trap' with a more accurate one.** A better trap would be: 'A common exam trap is confusing how security groups work with different connectivity options. Remember that you **can** reference security groups across a VPC Peering connection, but you **cannot** directly reference a security group in another VPC attached to a Transit Gateway. For TGW, you must rely on other controls like routing and NACLs.'\"}\n",
      "\n",
      "âœï¸ Revising article according to feedback...\n",
      "\n",
      "\n",
      "--- Round 3: Review ---\n",
      "\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 503 - [{'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalServerError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m topic = row[\u001b[33m\"\u001b[39m\u001b[33mTopic\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Processing topic: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m status, accepted_article = \u001b[43mprocess_topic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m df.at[i, \u001b[33m\"\u001b[39m\u001b[33mProcessed Date\u001b[39m\u001b[33m\"\u001b[39m] = datetime.now().strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m df.at[i, \u001b[33m\"\u001b[39m\u001b[33mStatus\u001b[39m\u001b[33m\"\u001b[39m] = status\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mprocess_topic\u001b[39m\u001b[34m(topic)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m round_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m):  \u001b[38;5;66;03m# up to 3 review-revise rounds\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Round \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mround_num\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Review ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     feedback = \u001b[43mreview_article\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(feedback)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m feedback[\u001b[33m\"\u001b[39m\u001b[33mno_more_revision\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mreview_article\u001b[39m\u001b[34m(article)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Use Gemini to review the OpenAI-generated article.\"\"\"\u001b[39;00m\n\u001b[32m     10\u001b[39m prompt = [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: reviewer_system_prompt}] + [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mArticle:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00marticle\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m}]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m response = \u001b[43mgemini\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m result = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Convert the type of feedback from string to json dict\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# # Try to find a JSON block in the string\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zhuyi\\Code\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zhuyi\\Code\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zhuyi\\Code\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zhuyi\\Code\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mInternalServerError\u001b[39m: Error code: 503 - [{'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}]"
     ]
    }
   ],
   "source": [
    "# --- Main Workflow ---\n",
    "if __name__ == \"__main__\":\n",
    "# === 1. Load the Excel file ===\n",
    "    input_file = \"topics.xlsx\"\n",
    "    df = pd.read_excel(input_file)\n",
    "\n",
    "# âœ… Explicitly cast to string/object dtype (fixes the warning)\n",
    "    df[\"Processed Date\"] = df[\"Processed Date\"].astype(\"string\")\n",
    "    df[\"Status\"] = df[\"Status\"].astype(\"string\")\n",
    "\n",
    "# === 2. Process only one topic per run ===\n",
    "    for i, row in df.iterrows():\n",
    "        status = str(row[\"Status\"]).strip()\n",
    "        if status == \"Completed\":\n",
    "            continue\n",
    "\n",
    "        topic = row[\"Topic\"]\n",
    "        print(f\"âœ… Processing topic: {topic}\")\n",
    "        status, accepted_article = process_topic(topic)\n",
    "        df.at[i, \"Processed Date\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        df.at[i, \"Status\"] = status\n",
    "\n",
    "# === 3. Write processed date and status back to Excel ===\n",
    "        df.to_excel(input_file, index=False)\n",
    "        print(f\"âœ… Processing complete. Results saved to {input_file}\")\n",
    "\n",
    "# === 4. Write the accepted article to Word ===\n",
    "        output_file = topic + \".docx\"\n",
    "        pypandoc.convert_text(\n",
    "            accepted_article,\n",
    "            'docx',\n",
    "            format='md',\n",
    "            outputfile=output_file,\n",
    "            extra_args=['--standalone']\n",
    "        )\n",
    "\n",
    "        print(f\"âœ… Accepted article saved to {output_file}\")\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        print(\"âœ… All topics already completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
